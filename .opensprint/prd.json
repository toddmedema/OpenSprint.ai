{
  "version": 2,
  "sections": {
    "executive_summary": {
      "content": "OpenSprint is a web application that guides users through the complete software development lifecycle using AI agents. It provides a structured, four-phase workflow — Spec, Plan, Execute, and Examine — that transforms high-level product ideas into working software with minimal manual intervention.\n\nThe platform pairs a browser-based interface with a background agent CLI, enabling AI to autonomously execute development tasks while keeping the user in control of strategy and direction. The core philosophy is that humans should focus on _what_ to build and _why_, while AI handles _how_ to build it.\n\nOpenSprint supports multiple agent backends (Claude, Cursor, and custom CLI agents), comprehensive automated testing including end-to-end and integration tests, configurable human-in-the-loop thresholds, and full offline operation for users with local agent setups.",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "problem_statement": {
      "content": "Building software with AI today is fragmented and unstructured. Developers use AI coding assistants for individual tasks, but there is no cohesive system that manages the full journey from idea to deployed product. This leads to several persistent problems:\n\n- **Lack of architectural coherence:** AI-generated code often lacks a unified vision because each prompt is handled in isolation, without awareness of the broader system design.\n- **No dependency tracking:** When building features in parallel, there is no mechanism to ensure that work on one feature accounts for dependencies on another.\n- **Manual orchestration overhead:** Users spend significant time managing prompts, context windows, and task sequencing rather than focusing on product decisions.\n- **No feedback loop:** There is no structured way to verify completed work and feed findings back into the development process.\n\nOpenSprint solves these problems by providing an end-to-end platform that maintains context across the entire lifecycle and automates the orchestration of AI development agents.\n\n",
      "version": 1,
      "updatedAt": "2026-02-15T09:08:59.834Z"
    },
    "goals_and_metrics": {
      "content": "### 3.1 Primary Goals\n\n1. Reduce the time from idea to working prototype by 10x compared to traditional AI-assisted development workflows.\n2. Enable non-engineers to ship production-quality software by handling technical complexity behind the scenes.\n3. Maintain architectural coherence across an entire project by flowing design decisions through every phase.\n4. Create a self-improving development flywheel where validation feedback automatically triggers corrective action.\n\n### 3.2 Success Metrics\n\n| Metric                              | Target                                     | Measurement Method               |\n| ----------------------------------- | ------------------------------------------ | -------------------------------- |\n| Time from idea to working prototype | < 1 day for standard web apps              | End-to-end session timing        |\n| User intervention rate during Execute | < 10% of tasks require manual input        | Task completion telemetry       |\n| Spec-to-code fidelity             | > 90% alignment with PRD                   | Automated PRD compliance checks  |\n| Feedback loop closure time          | < 30 min from bug report to fix deployed   | Examine-to-Execute cycle tracking |\n| First-time user task completion     | > 80% complete a full Spec-Execute cycle   | Onboarding funnel analytics      |\n| Test coverage                       | > 80% code coverage with passing E2E tests | Automated coverage reporting     |",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "user_personas": {
      "content": "### 4.1 The Product-Minded Founder\n\nA non-technical founder with a clear product vision who wants to build an MVP without hiring a development team. They understand what they want to build but need AI to handle the engineering. They value speed, clear communication about what is being built, and the ability to provide feedback without writing code.\n\n### 4.2 The Solo Developer\n\nAn experienced developer who wants to multiply their output. They can code but want to delegate routine implementation to AI while focusing on architecture and product decisions. They value transparency into what the AI is doing, the ability to intervene when needed, and high-quality code output.\n\n### 4.3 The Agency / Consultancy\n\nA small team that builds software for clients. They need to move quickly from client requirements to working software, maintain multiple projects simultaneously, and provide clients with visibility into progress. They value the structured workflow for client communication and the ability to run multiple projects in parallel.\n\n",
      "version": 1,
      "updatedAt": "2026-02-15T09:08:59.834Z"
    },
    "technical_architecture": {
      "content": "### 5.1 Architecture Overview\n\nOpenSprint consists of three primary layers: a web-based frontend, a backend API server, and a background agent CLI that executes development work. The frontend communicates with the backend via WebSockets for real-time updates and REST APIs for CRUD operations. The backend orchestrates agent CLI instances, manages project state, and maintains the living PRD.\n\nOpenSprint is designed to run entirely offline. The web frontend and backend API server run locally on the user's machine. When using a local agent CLI (such as a locally-hosted LLM), the entire development loop — from Spec through Examine — operates without any internet connectivity. Beads is git-based and inherently offline-compatible with no special synchronization logic required.\n\n### 5.2 Technology Stack\n\n**Backend:** Node.js with TypeScript. This provides a shared language and type system with the React frontend, mature WebSocket support, and robust subprocess management for agent CLIs via `child_process`. Beads is invoked via its CLI (`bd`) using `child_process.exec()` with `--json` flags for structured output.\n\n**Frontend:** React with TypeScript.\n\n### 5.3 Core Components\n\n| Component           | Technology                            | Responsibility                                                                                                                                                                                                                                                          |\n| ------------------- | ------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Web Frontend        | React + TypeScript                    | User interface for all four phases; real-time agent monitoring; project management                                                                                                                                                                                      |\n| Backend API         | Node.js + TypeScript                  | Project state management, WebSocket relay, PRD versioning, agent orchestration                                                                                                                                                                                          |\n| Agent CLI           | Pluggable (Claude, Cursor, Custom)    | Executes development tasks: code generation, testing, debugging                                                                                                                                                                                                         |\n| Orchestration Layer | Node.js (custom)                      | Agent lifecycle management (spawn, monitor, timeout), context assembly, retry logic, code review triggering. Delegates task prioritization and readiness to beads                                                                                                       |\n| Beads               | Git-based issue tracker (CLI: `bd`)   | Issue storage, dependency tracking (blocks/related/parent-child/discovered-from), ready-work detection and prioritization via `bd ready`, agent assignment via `assignee` field, hierarchical epic/task IDs, provenance via audit trail, JSONL-backed distributed state |\n| Version Control     | Git                                   | Code repository management, branch-per-task strategy                                                                                                                                                                                                                    |\n| Test Runner         | Configurable (Jest, Playwright, etc.) | Automated test execution and coverage reporting                                                                                                                                                                                                                         |\n| Deployment          | Expo.dev / Custom pipeline            | Automated deployment for supported platforms                                                                                                                                                                                                                            |\n\n### 5.4 Beads Integration Details\n\n[Beads](https://github.com/steveyegge/beads) provides the persistence, dependency, and scheduling layer. OpenSprint's orchestration layer is thin and delegates heavily to beads.\n\n**What beads provides natively (and OpenSprint uses directly):**\n\n- Issue CRUD with priorities (0-4), statuses (open/in_progress/closed), assignees, labels, and types (bug/feature/task/epic/chore)\n- Four dependency types: blocks, related, parent-child, discovered-from\n- `bd ready --json` — finds issues with no open blockers, sorted by priority. This is OpenSprint's execute queue — the orchestrator simply calls `bd ready` and picks the first result\n- `assignee` field — the orchestrator uses `bd update <id> --assignee agent-<id>` to track which agent is working on a task\n- Hierarchical child IDs (e.g., `bd-a3f8.1`, `bd-a3f8.2`) for epic → task breakdown\n- JSON output on all commands for programmatic integration\n- Hash-based collision-resistant IDs\n- Git-backed JSONL storage with auto-sync\n- Daemon with real-time event capabilities\n- Full audit trail of every change\n\n**Planning state via gating task:** When a Plan is created and its tasks are decomposed, the orchestrator creates a special gating task as the first child of the epic (e.g., `bd-a3f8.0` titled \"Plan approval gate\"). All real implementation tasks have a `blocks` dependency on this gate. While the gate is open, `bd ready` will not return any of the implementation tasks. When the user clicks \"Execute it!\", the gate task is closed, which unblocks all child tasks and makes them eligible for `bd ready` based on their own inter-task dependencies. The epic itself stays open throughout the execute process and is only closed when all child tasks are Done.\n\n**What OpenSprint's orchestration layer adds:**\n\n- Agent lifecycle management: spawning, monitoring, 5-minute timeout handling, and teardown of CLI processes\n- Context assembly: gathering PRD sections, Plan markdowns, and upstream task outputs into a prompt for each agent\n- Two-agent review cycle: coding agent implements, review agent validates (see Section 7.3.2)\n- Retry and failure handling: reverting failed attempts, adding failure context to bead comments, re-queuing tasks\n\n### 5.5 Data Flow\n\nThe data flows through the system in a unidirectional pipeline with feedback loops. User input in Spec creates or updates the PRD. The PRD is decomposed in Plan into feature-level Plan markdown files, each representing an epic. In Execute, Plan markdowns are further broken into individual tasks mapped to beads for dependency tracking. Agent CLIs pick up tasks, execute them, and report results back through the system. In Examine, user feedback is mapped back to the relevant Plan epic and Execute tasks, creating new tickets as needed. Any changes at any phase propagate upstream to update the living PRD, ensuring the document always reflects the current state of the project.\n\n## 6. Project Setup & Configuration\n\n### 6.1 Home Screen & Project Management\n\nOpenSprint opens to a home screen that lists all existing projects as cards, each showing the project name, last-modified date, current phase, and overall progress. A prominent \"Create New Project\" button starts the project setup wizard.\n\nOnce inside a project, the project name appears at the top-left of the navbar and functions as a dropdown selector. Clicking it reveals a list of all projects, allowing the user to rapidly switch between projects without returning to the home screen.\n\n### 6.2 Project Setup Wizard\n\nCreating a new project follows a sequential wizard:\n\n1. **Project name and description** — basic metadata.\n2. **Agent configuration** — select planning agent and coding agent (see 6.3).\n3. **Deployment configuration** — select deployment mode (see 6.4).\n4. **Human-in-the-loop preferences** — configure autonomy thresholds (see 6.5).\n5. **Repository initialization** — OpenSprint creates a git repo and runs `bd init` to set up beads.\n\nAfter setup, the user lands directly in the Spec tab.\n\n### 6.3 Agent Configuration\n\nUsers configure two separate agents during project setup. Both use the same invocation mechanism — OpenSprint calls the user-selected agent's API or CLI for all phases (Spec conversations, Plan decomposition, Execute coding, Execute review). The only difference is which agent/model is used.\n\n**Planning Agent** (used in Spec and Plan phases):\n\n- Handles conversational PRD creation, feature decomposition, Plan markdown generation, PRD update reviews, and feedback analysis in the Examine phase.\n- Options: Claude (select model: e.g., Sonnet, Opus), Cursor (select model from available options), or Custom (user provides CLI command).\n- When Claude or Cursor is selected, OpenSprint queries the provider's API for available models and populates a model dropdown.\n\n**Coding Agent** (used in Execute phase):\n\n- Handles task implementation, code generation, testing, debugging, and code review.\n- Same options as Planning Agent, configured independently.\n- Users may choose the same agent/model for both, or different ones (e.g., Opus for planning, Sonnet for coding to manage costs).\n\nThe agent configuration can be changed at any time from project settings. When switching coding agents mid-project, all pending tasks in the Ready state will be picked up by the newly selected agent. In-progress tasks will complete with their originally assigned agent.\n\n### 6.4 Deployment Configuration\n\nOpenSprint supports two deployment modes that users configure during project setup:\n\n- **Expo.dev integration (default for mobile/web):** OpenSprint can automatically deploy to Expo.dev for React Native and web projects. The system manages EAS Build configuration, over-the-air updates, and preview deployments for the Examine phase. Each completed Execute cycle triggers an automatic preview deployment. Requires internet connectivity.\n- **Custom deployment pipeline:** Users can connect their own deployment pipeline by specifying a deployment command or webhook URL. OpenSprint will trigger this pipeline after successful Execute completion and test passage. This supports any CI/CD system (GitHub Actions, Vercel, Netlify, AWS, etc.).\n\n### 6.5 Human-in-the-Loop Configuration\n\nOpenSprint is designed to operate as an autonomous flywheel, but users have granular control over when the system pauses for human input. During project setup (and adjustable at any time), users configure their autonomy preferences via a series of checkboxes organized into four decision categories.\n\n#### 6.5.1 Decision Categories\n\n| Category                 | What It Covers                                                                                                                                                                                            | Default                                   |\n| ------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- |\n| Scope Changes            | Any modification that adds, removes, or substantially alters a feature in the PRD. This includes changes triggered by Examine feedback that the AI determines represent new scope rather than bug fixes. | Requires approval                         |\n| Architecture Decisions   | Technology stack changes, new external service integrations, database schema modifications, API contract changes, and significant refactors that alter system structure.                                  | Requires approval                         |\n| Dependency Modifications | Changes to task ordering, adding new dependencies between epics, splitting or merging tasks, and re-prioritization of the execute queue.                                                                    | Automated                                 |\n| Test Failures & Retries  | How to handle tasks where automated tests fail after agent completion: retry with the same agent, retry with modified instructions, or escalate to the user.                                              | Automated (retry up to 2x, then escalate) |\n\n#### 6.5.2 Notification Behavior\n\nFor each category, users choose one of three modes:\n\n- **Automated:** The AI makes the decision autonomously and notifies the user after the fact via a log entry. The flywheel continues without pausing.\n- **Notify and proceed:** The AI makes the decision, sends a real-time notification to the user, and continues without waiting. The user can review and override retroactively if needed.\n- **Requires approval:** The AI prepares a recommendation with full context, pauses the affected work stream, and waits for explicit user approval before proceeding. Other non-blocked work continues in parallel.\n\nThis configuration ensures that users who want full autonomy can get it, while users who want tight control over critical decisions have that option. The system defaults to requiring approval for the two highest-impact categories (Scope Changes, Architecture Decisions) and automating the two more operational categories.\n\n## 17. Technical Constraints & Assumptions\n\n### 17.1 Constraints\n\n- The agent CLI must operate within a sandboxed environment with controlled filesystem and network access.\n- Agent context windows are finite; the system must manage context efficiently, providing only the relevant PRD sections, Plan details, and dependency outputs for each task. V1 uses a simple context assembly strategy (Plan + dependency diffs); v2 will introduce a conductor agent for intelligent summarization.\n- Real-time streaming of agent output requires persistent WebSocket connections.\n- Beads integration is git-based and inherently offline-compatible; no special synchronization logic required.\n- Custom agent support requires the agent to accept a file path argument pointing to the task prompt and produce a `result.json` file on completion.\n- OpenSprint must be fully functional without an internet connection; all core features (Spec, Plan, Execute, Examine) must work offline when paired with a local agent.\n- V1 runs a single agent at a time to eliminate merge conflict concerns. Concurrent agent execution is a v2 feature.\n\n### 17.2 Assumptions\n\n- Users have a basic understanding of software concepts (features, bugs, requirements) even if they cannot code.\n- AI agent capabilities will continue to improve, making the autonomous Execute phase increasingly reliable over time.\n- Initial release targets web and React Native application development; other platforms will follow.\n- Users deploying via Expo.dev have or will create an Expo account during project setup (online mode only).\n- Offline users have sufficient local compute to run their chosen agent CLI and the OpenSprint application simultaneously.\n\n## 14. Beads Command Reference\n\nAll beads interactions use the `bd` CLI with `--json` flags, invoked via `child_process.exec()` from the Node.js backend.\n\n| Command                                                     | When Used                             | Purpose                                                      |\n| ----------------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------ |\n| `bd init`                                                   | Project setup                         | Initialize beads in the project repo                         |\n| `bd create \"<title>\" -t <type> -p <priority> --json`        | Plan decomposition, Examine feedback | Create epics, tasks, and bug tickets                         |\n| `bd update <id> --status <status> --json`                   | Orchestrator state transitions        | Move tasks between open/in_progress/closed                   |\n| `bd update <id> --assignee <agent-id> --json`               | Orchestrator task assignment          | Track which agent is working on a task                       |\n| `bd update <id> -d \"<description>\" --json`                  | Plan creation                         | Set epic description to Plan markdown path                   |\n| `bd close <id> --reason \"<reason>\" --json`                  | Execute it!, task completion          | Close gating tasks, completed tasks                          |\n| `bd ready --json`                                           | Orchestrator execute loop             | Get next available task (priority-sorted, all deps resolved) |\n| `bd list --json`                                            | Execute tab, task listing             | List all tasks with filters                                  |\n| `bd show <id> --json`                                       | Task detail panel                     | Get full task details                                        |\n| `bd dep add <id> <blocker-id> --json`                       | Plan decomposition                    | Add blocks/parent-child dependencies                         |\n| `bd dep add <id> <parent-id> --type discovered-from --json` | Examine feedback                     | Link feedback tasks to source                                |\n| `bd dep tree <id>`                                          | Dependency graph visualization        | Visualize dependency relationships                          |\n| `bd delete <id> --force --json`                             | Plan re-execute (no work started)     | Remove obsolete tasks                                        |",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "feature_list": {
      "content": "### 7.1 Spec Phase\n\n#### 7.1.1 Purpose\n\nThe Spec phase is where the user collaborates with the planning agent to define what they are building and why. The output is a living PRD that serves as the single source of truth for the entire project.\n\n#### 7.1.2 Key Capabilities\n\n- **Conversational PRD creation:** The user describes their product vision in natural language. The AI asks clarifying questions, challenges assumptions, identifies edge cases, and collaboratively builds out the PRD.\n- **Living document:** The PRD is version-controlled and automatically updated whenever changes are made in the Plan, Execute, or Examine phases. Users can view the full change history and understand why each change was made.\n- **Architecture definition:** The AI helps define the technical architecture, including tech stack selection, system components, data models, and API contracts.\n- **Mockup generation:** The AI generates UI mockups or wireframes based on the product description, which the user can iterate on within the conversation.\n- **Proactive challenge:** The AI actively identifies potential issues, asking questions like \"What happens when this service is unavailable?\" or \"Have you considered rate limiting on this endpoint?\"\n\n#### 7.1.3 PRD Structure\n\nThe living PRD generated in this phase includes the following sections: Executive Summary, Problem Statement, User Personas, Goals and Success Metrics, Feature List with Priorities, Technical Architecture, Data Model, API Contracts, Non-Functional Requirements, and Open Questions. Each section is independently versioned so that downstream changes only update the relevant portions.\n\n#### 7.1.4 PRD Storage\n\nThe living PRD is stored as a structured JSON file within the project's git repository at `.opensprint/prd.json`. Each section is a top-level key with its content stored as markdown text, enabling independent versioning and targeted updates. The JSON wrapper allows the backend to subscribe to changes at the section level, diff individual sections, and merge updates from different phases without conflicts. Git history provides the full version timeline. The frontend renders each section's markdown content as a readable document.\n\n#### 7.1.5 User Interface\n\nThe Spec tab presents a split-pane interface. The left pane is a chat window where the user converses with the planning agent. The right pane displays the live PRD document, updating in real-time as the conversation progresses. Users can click on any section of the PRD to focus the conversation on that area, or edit the PRD directly with changes reflected back into the conversation context.\n\n### 7.2 Plan Phase\n\n#### 7.2.1 Purpose\n\nThe Plan phase breaks the high-level PRD into discrete, implementable features. Each feature becomes a Plan markdown file that fully specifies what needs to be built, serving as the epic-level unit of work.\n\n#### 7.2.2 Key Capabilities\n\n- **AI-assisted decomposition:** The planning agent analyzes the PRD and suggests a breakdown into features. The user can accept, modify, merge, or split the suggested features.\n- **Plan markdown specification:** Each feature is documented in a structured markdown file stored at `.opensprint/plans/<plan-id>.md`, containing: overview, acceptance criteria, technical approach, dependencies on other Plans, data model changes, API endpoints, UI components, edge cases, and testing strategy.\n- **Dependency graph visualization:** A visual graph shows how features relate to each other, highlighting critical paths and potential bottlenecks. This helps the user understand implementation order before committing to the Execute phase.\n- **Suggested implementation order:** The AI recommends an execute sequence based on dependency analysis, risk assessment, and foundational priority — executing the riskiest and most foundational pieces first.\n- **Upstream propagation:** Any changes made to Plans (additions, modifications, scope changes) are automatically reflected back in the living PRD. When a Plan is approved for execute, the orchestrator invokes the planning agent to review the Plan against the current PRD and update any affected sections. The agent receives the full PRD and the approved Plan as context and produces targeted section updates with change log entries.\n- **\"Execute it!\" transition:** Plans and their decomposed tasks exist in a Planning state — all implementation tasks have a `blocks` dependency on a gating task (`bd-a3f8.0 \"Plan approval gate\"`), so they do not appear in `bd ready`. Each Plan card in the Plan view has an \"Execute it!\" button that closes the gating task, allowing child tasks to become eligible for `bd ready` based on their own inter-task dependencies. This prevents agents from working on features that are still being refined.\n- **Re-execute behavior:** A Plan can only be re-executed once ALL tasks in its existing epic are Done (or if no work has been started yet, in which case all existing sub-tasks are simply deleted). The \"Re-execute\" button is disabled if any tasks are currently In Progress or In Review. When clicked, the system generates new tasks representing the delta between the updated Plan and the completed work. The AI reasons about this as it would any new feature, but with the context of what has already been built.\n\n#### 7.2.3 Plan Markdown Structure\n\nEach Plan markdown file follows a standardized template: Feature Title, Overview, Acceptance Criteria (with testable conditions), Technical Approach, Dependencies (references to other Plan files), Data Model Changes, API Specification, UI/UX Requirements, Edge Cases and Error Handling, Testing Strategy, and Estimated Complexity. This structure ensures that every Plan contains sufficient detail for an AI agent to implement it without ambiguity.\n\n#### 7.2.4 User Interface\n\nThe Plan tab displays a card-based interface showing all feature Plans, with a dependency graph visualization at the top. Each card shows the feature title, status (Planning/Executing/Complete), complexity estimate, and dependency count. Users can click into any Plan to view or edit the full markdown. A sidebar allows conversational interaction with the planning agent to refine individual Plans. Each Plan card has an \"Execute it!\" button (or \"Re-execute\" for completed Plans with pending changes; disabled if any tasks are In Progress or In Review).\n\n### 7.3 Execute Phase\n\n#### 7.3.1 Purpose\n\nThe Execute phase is where AI agents autonomously implement the planned features. Plan markdowns are decomposed into individual tasks, organized on a kanban board, and executed by background agent CLIs with full dependency awareness.\n\n#### 7.3.2 Key Capabilities\n\n- **Automatic task decomposition:** Each Plan markdown is broken down into granular, atomic tasks. The planning agent determines task boundaries to maximize future parallelism while respecting dependencies. Tasks are created as beads child issues under the Plan's epic (e.g., `bd-a3f8.1`, `bd-a3f8.2`), each with a `blocks` dependency on the epic's gating task (`bd-a3f8.0`) to keep them in Planning state until the user clicks \"Execute it!\".\n- **Beads-based tracking:** Each Plan maps to a bead epic. The Plan markdown file (`.opensprint/plans/<plan-id>.md`) is attached to the bead epic as its design document metadata — the epic's description field contains the path to the Plan markdown, making the Plan the authoritative specification for all child tasks under that epic. Each task maps to a child bead within that epic. Beads provides dependency tracking, ready-work detection via `bd ready`, agent assignment via the `assignee` field, and the distributed git-backed storage.\n- **Kanban board interface:** Tasks are displayed across columns: Planning, Backlog, Ready, In Progress, In Review, Done. Tasks move automatically as agents pick them up and complete them.\n- **Two-agent execute cycle:** Each task is processed by two agents sequentially. First, a **coding agent** picks up the task, moves it to In Progress, implements the solution, writes tests, and moves it to In Review. Then, a **review agent** is automatically triggered to verify the implementation against the ticket specification, verify that tests pass and adequately cover the ticket scope, and check code quality. If the review agent approves, it moves the task to Done. If it rejects, it adds detailed feedback as a comment on the bead issue and moves the task back to In Progress, triggering a new coding agent with the original prompt plus the review feedback. This cycle repeats until the review agent approves or the retry limit is reached.\n- **Autonomous single-agent execution:** The orchestration layer runs one agent at a time (coding or review). It polls `bd ready --json` to find the next available task, assigns it via `bd update <id> --assignee agent-1`, and manages the full execution lifecycle. This is designed as a flywheel that runs in the background without requiring constant user intervention.\n- **Real-time agent monitoring:** Users can click on any In Progress or In Review task to see a live stream of the agent's reasoning, code generation, and decision-making. Completed tasks display the full output log and generated artifacts.\n- **Context propagation:** When Task B depends on Task A, the agent picking up Task B receives not just the Plan, but also the actual output and code produced by Task A. This ensures agents build on reality, not just plans. (Note: for v1, context is assembled from the Plan markdown plus the git diff/files produced by dependency tasks. A dedicated \"conductor\" agent for intelligent context summarization is planned for v2 to support large projects.)\n\n#### 7.3.3 Task Lifecycle & State Machine\n\n| State       | Beads Representation                                    | Description                                                                                                                                                                                                                                              |\n| ----------- | ------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Planning    | `status: open` + `blocks` dep on gating task            | Task exists but is not ready for implementation; gating task still open                                                                                                                                                                                  |\n| Backlog     | `status: open` (gate closed, has other unresolved deps) | Task is approved for implementation; waiting on other task dependencies                                                                                                                                                                                  |\n| Ready       | Returned by `bd ready`                                  | All blocking dependencies resolved; available for agent pickup                                                                                                                                                                                           |\n| In Progress | `status: in_progress` + `assignee: agent-1`             | Coding agent actively implementing the task. Sub-phase (coding vs review) tracked in `.opensprint/active/<task-id>/config.json` `phase` field.                                                                                                               |\n| In Review   | `status: in_progress` + `assignee: agent-1`             | Review agent validating the implementation. Beads does not have a native `in_review` status, so this is the same beads state as In Progress — the distinction is tracked in the orchestrator's config (`phase: \"review\"`) and reflected in the frontend. |\n| Done        | `status: closed` + `close reason`                       | Task completed; review agent approved; all tests passing                                                                                                                                                                                                 |\n\n**Valid State Transitions:**\n\n```\nPlanning → Backlog          (user clicks \"Execute it!\" — gating task closed)\nBacklog → Ready             (all blocking dependencies resolve — automatic via bd ready)\nReady → In Progress         (orchestrator assigns coding agent)\nIn Progress → In Review     (coding agent completes — review agent triggered)\nIn Review → Done            (review agent approves)\nIn Review → In Progress     (review agent rejects — feedback added to bead, new coding agent triggered)\nIn Progress → Ready         (coding agent fails — changes rolled back, comment added to bead)\nDone → (terminal)           (tasks cannot be reopened; new tasks are created instead)\n```\n\n**Transition Guards:**\n\n- `Planning → Backlog`: Requires the gating task (`bd-a3f8.0`) to be closed (via \"Execute it!\").\n- `Backlog → Ready`: Checked by `bd ready` — all `blocks` dependencies must be `closed`.\n- `Ready → In Progress`: Orchestrator must not have another agent currently running (single-agent execution in v1).\n- `In Progress → In Review`: Coding agent process has exited and produced a `result.json` with `status: success`.\n- `In Review → Done`: Review agent approves the implementation; all automated tests pass.\n- `In Review → In Progress`: Review agent rejects; feedback comment is added to bead issue; attempt count incremented. If retry limit reached, escalates per HIL config.\n- `In Progress → Ready`: Coding agent fails or times out (5-minute inactivity timeout); all git changes reverted; failure comment added to bead issue.\n\n#### 7.3.4 User Interface\n\nThe Execute tab presents a kanban board with swimlanes grouped by Plan epic. Each task card shows the task title, status, assigned agent, and elapsed time. Clicking a card opens a detail panel with the full task specification, live agent output stream (for in-progress or in-review tasks), or completed work artifacts (for done tasks). A top-level progress bar shows overall project completion.\n\n### 7.4 Examine Phase\n\n#### 7.4.1 Purpose\n\nThe Examine phase closes the feedback loop. Users test the built software on their own, then provide feedback, bug reports, and improvement suggestions through OpenSprint. The AI maps this feedback to the appropriate Plan epics and Execute tasks, automatically creating new tickets to address issues.\n\n#### 7.4.2 Key Capabilities\n\n- **Feedback submission:** Users submit feedback in natural language via a simple input prompt. The AI categorizes feedback as bug reports, feature requests, UX improvements, or scope changes.\n- **Intelligent mapping:** The planning agent analyzes each piece of feedback and determines which Plan epic and Execute task(s) it relates to. It then creates new bead tickets under the appropriate epic with full context about the issue.\n- **Automatic PRD updates:** When feedback is submitted and the planning agent categorizes it as a scope change, the agent reviews the feedback against the current PRD and determines if updates are necessary. If so, it produces targeted section updates. Scope changes require user approval based on the Human-in-the-Loop configuration before the PRD is modified.\n- **Flywheel operation:** Once new tickets are created from validation feedback, they automatically enter the Execute phase task queue. Agents pick them up and implement fixes without requiring the user to manually manage the process. This creates a continuous improvement cycle.\n- **Feedback history:** A scrollable feed tracks all submitted feedback items, their mapped location in the project (which Plan/task), and the current resolution status.\n\n#### 7.4.3 User Interface\n\nThe Examine tab presents a simple interface. At the top is a text input area where the user describes their feedback. Below it is a chronological feed of all submitted feedback items, each showing: the original feedback text, the AI's categorization (bug/feature/UX/scope), the mapped Plan epic and created task(s), and the current status of those tasks. Users test their application independently outside OpenSprint and return here to report findings.",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "data_model": {
      "content": "### 10.1 Entity Relationship Overview\n\n```\nUser (implicit, single-user)\n  └── Project (1:many)\n        ├── PRD (1:1, JSON file)\n        ├── AgentConfig (1:1, embedded in project settings)\n        ├── Conversation (1:many, per phase/context)\n        │     └── Message (1:many, ordered)\n        ├── Plan (1:many, markdown files)\n        │     └── Task (1:many, beads issues with parent-child IDs)\n        │           └── AgentSession (1:many, per attempt)\n        ├── FeedbackItem (1:many)\n        └── Settings (1:1, project configuration)\n```\n\n### 10.2 Entity Definitions\n\n#### Project\n\n| Field         | Type          | Description                         |\n| ------------- | ------------- | ----------------------------------- |\n| id            | string (UUID) | Unique project identifier           |\n| name          | string        | Display name                        |\n| description   | string        | Brief project description           |\n| repo_path     | string        | Absolute path to the git repository |\n| created_at    | datetime      | Creation timestamp                  |\n| updated_at    | datetime      | Last modification timestamp         |\n| current_phase | enum          | spec / plan / execute / examine      |\n\n#### PRD\n\nStored as `.opensprint/prd.json` in the project repo. Each section's content is stored as markdown. Structure:\n\n```json\n{\n  \"version\": 12,\n  \"sections\": {\n    \"executive_summary\": { \"content\": \"## Executive Summary\\n\\nThis product...\", \"version\": 5, \"updated_at\": \"...\" },\n    \"problem_statement\": { \"content\": \"## Problem Statement\\n\\nUsers face...\", \"version\": 3, \"updated_at\": \"...\" },\n    \"user_personas\": { \"content\": \"## User Personas\\n\\n### Persona 1...\", \"version\": 2, \"updated_at\": \"...\" }\n  },\n  \"change_log\": [\n    { \"section\": \"executive_summary\", \"version\": 5, \"source\": \"examine\", \"timestamp\": \"...\", \"diff\": \"...\" }\n  ]\n}\n```\n\n#### Conversation\n\nStored as `.opensprint/conversations/<conversation-id>.json`. Conversations are created per phase context (one for the main Spec chat, one per Plan sidebar chat).\n| Field | Type | Description |\n|-------|------|-------------|\n| id | string (UUID) | Unique conversation identifier |\n| context | enum | spec / plan:<plan-id> | Which phase/plan this conversation belongs to |\n| messages | array | Ordered list of messages |\n\nEach message in the array:\n| Field | Type | Description |\n|-------|------|-------------|\n| role | enum | user / assistant | Who sent the message |\n| content | string | Message text (markdown) |\n| timestamp | datetime | When the message was sent |\n| prd_changes | object[] | Optional: PRD sections modified as a result of this message |\n\n#### Plan\n\nStored as `.opensprint/plans/<plan-id>.md` in the project repo. The Plan markdown file is associated to its bead epic as the design document metadata — the epic's `description` field contains the path to the Plan markdown file (e.g., `.opensprint/plans/auth.md`), making the Plan the authoritative specification that agents reference when implementing child tasks. Additional metadata:\n| Field | Type | Description |\n|-------|------|-------------|\n| plan_id | string | Unique identifier (matches filename) |\n| bead_epic_id | string | Corresponding beads epic ID (e.g., `bd-a3f8`). Plan status (planning/executing/complete) is derived from the beads epic state — no separate status field needed. |\n| gate_task_id | string | The gating task ID (e.g., `bd-a3f8.0`) — closed when user clicks \"Execute it!\" |\n| shipped_at | datetime | When the user clicked \"Execute it!\" (null if still in planning) |\n| complexity | enum | low / medium / high / very_high |\n\n#### Task\n\nRepresented as beads issues (child IDs under the Plan's epic). OpenSprint reads/writes these via `bd` commands. Key fields managed by beads:\n| Field | Source | Description |\n|-------|--------|-------------|\n| id | beads | Hash-based ID (e.g., `bd-a3f8.1`) |\n| title | beads | Task title |\n| description | beads | Task specification |\n| status | beads | open / in_progress / closed |\n| priority | beads | 0-4 (0 = highest) |\n| assignee | beads | Agent instance ID when in progress |\n| labels | beads | User-defined labels for categorization |\n| dependencies | beads | `blocks` relationships to other tasks |\n\n#### AgentSession\n\nStored as `.opensprint/sessions/<task-id>-<attempt>.json`:\n| Field | Type | Description |\n|-------|------|-------------|\n| task_id | string | The beads task ID |\n| attempt | number | Attempt number (1, 2, 3...) |\n| agent_type | string | claude / cursor / custom |\n| agent_model | string | Specific model used |\n| started_at | datetime | When the agent began |\n| completed_at | datetime | When the agent finished |\n| status | enum | success / failed / timeout / cancelled / approved / rejected |\n| output_log | string (filepath) | Path to full agent output log |\n| git_branch | string | Branch the agent worked on |\n| git_diff | string (filepath) | Path to the produced diff |\n| test_results | object | Test pass/fail counts and details |\n| failure_reason | string | If failed, why |\n\n#### FeedbackItem\n\nStored as `.opensprint/feedback/<feedback-id>.json`:\n| Field | Type | Description |\n|-------|------|-------------|\n| id | string (UUID) | Unique feedback identifier |\n| text | string | User's feedback in natural language |\n| category | enum | bug / feature / ux / scope |\n| mapped_plan_id | string | Plan epic the feedback maps to |\n| created_task_ids | string[] | Beads task IDs created from this feedback |\n| status | enum | pending / mapped / resolved |\n| created_at | datetime | Submission timestamp |\n\n#### ProjectSettings\n\nStored as `.opensprint/settings.json`:\n| Field | Type | Description |\n|-------|------|-------------|\n| planning_agent | object | `{ type, model, cli_command }` |\n| coding_agent | object | `{ type, model, cli_command }` |\n| deployment | object | `{ mode, expo_config, custom_command }` |\n| hil_config | object | Per-category notification mode settings |\n| test_framework | string | Detected or user-selected test framework |\n\n### 10.3 Storage Strategy\n\n**Project Index:** A global project index is stored at `~/.opensprint/projects.json` on the user's machine. This file maps project IDs to their repository paths, enabling the home screen to discover and list all projects:\n\n```json\n{\n  \"projects\": [\n    { \"id\": \"uuid-1\", \"name\": \"MyApp\", \"repo_path\": \"/Users/me/projects/myapp\", \"created_at\": \"...\" },\n    { \"id\": \"uuid-2\", \"name\": \"ClientSite\", \"repo_path\": \"/Users/me/projects/clientsite\", \"created_at\": \"...\" }\n  ]\n}\n```\n\nThis file is the only OpenSprint data stored outside of project repositories. It is not version-controlled.\n\n**Per-Project Data:** All other OpenSprint data is stored as files within the project's git repository under the `.opensprint/` directory. This means:\n\n- Everything is version-controlled automatically.\n- Everything works offline with no external database.\n- Everything syncs via git push/pull if the user has a remote.\n- Beads issues are stored in `.beads/` (managed by beads itself).\n- OpenSprint metadata is stored in `.opensprint/` (managed by OpenSprint).\n\nThe OpenSprint backend maintains an in-memory index of project data for fast queries, rebuilt from the filesystem on startup (similar to how beads uses SQLite as a cache over JSONL).",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "api_contracts": {
      "content": "### 11.1 REST API\n\nAll endpoints are prefixed with `/api/v1`. Responses are JSON.\n\n#### Projects\n\n| Method | Endpoint        | Description                                      |\n| ------ | --------------- | ------------------------------------------------ |\n| GET    | `/projects`     | List all projects                                |\n| POST   | `/projects`     | Create a new project (runs setup wizard backend) |\n| GET    | `/projects/:id` | Get project details                              |\n| PUT    | `/projects/:id` | Update project settings                          |\n| DELETE | `/projects/:id` | Delete a project                                 |\n\n#### PRD\n\n| Method | Endpoint                     | Description                   |\n| ------ | ---------------------------- | ----------------------------- |\n| GET    | `/projects/:id/prd`          | Get full PRD                  |\n| GET    | `/projects/:id/prd/:section` | Get a specific PRD section    |\n| PUT    | `/projects/:id/prd/:section` | Update a specific PRD section |\n| GET    | `/projects/:id/prd/history`  | Get PRD change log            |\n\n#### Plans\n\n| Method | Endpoint                             | Description                                               |\n| ------ | ------------------------------------ | --------------------------------------------------------- |\n| GET    | `/projects/:id/plans`                | List all Plans with status                                |\n| POST   | `/projects/:id/plans`                | Create a new Plan                                         |\n| GET    | `/projects/:id/plans/:planId`        | Get Plan markdown and metadata                            |\n| PUT    | `/projects/:id/plans/:planId`        | Update Plan markdown                                      |\n| POST   | `/projects/:id/plans/:planId/ship`   | Execute it! (transition tasks from Planning to Backlog)   |\n| POST   | `/projects/:id/plans/:planId/rebuild` | Re-execute an updated Plan (with confirmation)           |\n| GET    | `/projects/:id/plans/dependencies`   | Get dependency graph data                                 |\n\n#### Tasks (read-through to beads)\n\n| Method | Endpoint                                        | Description                               |\n| ------ | ----------------------------------------------- | ----------------------------------------- |\n| GET    | `/projects/:id/tasks`                           | List all tasks (wraps `bd list --json`)   |\n| GET    | `/projects/:id/tasks/ready`                     | Get ready tasks (wraps `bd ready --json`) |\n| GET    | `/projects/:id/tasks/:taskId`                   | Get task details (wraps `bd show --json`) |\n| GET    | `/projects/:id/tasks/:taskId/sessions`          | Get agent sessions for a task             |\n| GET    | `/projects/:id/tasks/:taskId/sessions/:attempt` | Get specific agent session output         |\n\n#### Execute Orchestration\n\n| Method | Endpoint                       | Description                                                          |\n| ------ | ------------------------------ | -------------------------------------------------------------------- |\n| POST   | `/projects/:id/execute/start`  | Start the execute orchestrator                                       |\n| POST   | `/projects/:id/execute/pause`  | Pause the execute orchestrator                                       |\n| GET    | `/projects/:id/execute/status` | Get orchestrator status (running/paused, active agents, queue depth) |\n\n#### Examine\n\n| Method | Endpoint                             | Description                           |\n| ------ | ------------------------------------ | ------------------------------------- |\n| GET    | `/projects/:id/feedback`             | List all feedback items               |\n| POST   | `/projects/:id/feedback`             | Submit new feedback                   |\n| GET    | `/projects/:id/feedback/:feedbackId` | Get feedback details and mapped tasks |\n\n#### Chat (Spec & Plan conversation)\n\n| Method | Endpoint                     | Description                                                  |\n| ------ | ---------------------------- | ------------------------------------------------------------ |\n| POST   | `/projects/:id/chat`         | Send a message to the planning agent; returns agent response |\n| GET    | `/projects/:id/chat/history` | Get conversation history                                     |\n\n### 11.2 WebSocket Events\n\nConnection: `ws://localhost:<port>/ws/projects/:id`\n\n**Server → Client events:**\n| Event | Payload | Description |\n|-------|---------|-------------|\n| `task.updated` | `{ taskId, status, assignee }` | Task state changed |\n| `agent.output` | `{ taskId, chunk }` | Streaming agent output for a task |\n| `agent.completed` | `{ taskId, status, testResults }` | Agent finished a task |\n| `prd.updated` | `{ section, version }` | PRD section was updated |\n| `execute.status` | `{ running, currentTask, queueDepth }` | Orchestrator status change |\n| `hil.request` | `{ category, description, options }` | Human-in-the-loop approval needed |\n| `feedback.mapped` | `{ feedbackId, planId, taskIds }` | Feedback was mapped to tasks |\n\n**Client → Server events:**\n| Event | Payload | Description |\n|-------|---------|-------------|\n| `agent.subscribe` | `{ taskId }` | Start streaming agent output for a task |\n| `agent.unsubscribe` | `{ taskId }` | Stop streaming agent output |\n| `hil.respond` | `{ requestId, approved, notes }` | Respond to a HIL request |",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "non_functional_requirements": {
      "content": "### 8.1 Philosophy\n\nOpenSprint takes an aggressive approach to automated testing. Every task completed by an AI agent must be accompanied by comprehensive tests. Testing is not optional or best-effort — it is a core requirement of task completion. A task is not considered Done until its tests pass.\n\n### 8.2 Testing Layers\n\n| Layer             | Scope                                                                     | When Generated                                            | When Run                                            |\n| ----------------- | ------------------------------------------------------------------------- | --------------------------------------------------------- | --------------------------------------------------- |\n| Unit Tests        | Individual functions and components                                       | Created by the agent as part of each task                 | On task completion; on every subsequent code change |\n| Integration Tests | Interactions between modules, API contracts, data flow between components | Created when a task involves multi-component interaction  | After dependent tasks complete; on every build      |\n| End-to-End Tests  | Full user flows through the application, simulating real user behavior    | Created per Plan epic once all tasks in the epic are Done | After epic completion; on every deployment         |\n| Regression Tests  | Ensure that fixes from Examine do not break existing functionality        | Auto-generated when an Examine ticket is resolved         | On every subsequent build                           |\n\n### 8.3 Test Execution\n\nThe test runner is configurable during project setup. OpenSprint supports common testing frameworks (Jest, Vitest, Playwright, Cypress, pytest, etc.) and will detect or recommend the appropriate framework based on the project's tech stack. Test results are displayed in the Execute tab alongside task status. Failed tests block a task from moving to Done and trigger either an automatic retry or escalation based on the Human-in-the-Loop configuration.\n\n### 8.4 Coverage Requirements\n\nOpenSprint targets a minimum of 80% code coverage across all generated code. Coverage reports are generated after each Execute cycle and displayed in the project dashboard. The AI agent is instructed to prioritize testing edge cases and error handling paths identified in the Plan markdown, not just happy paths.\n\n## 15. Cross-Cutting Concerns\n\n### 15.1 Living PRD Synchronization\n\nThe living PRD is the backbone of OpenSprint. Changes propagate to the PRD at two trigger points: (1) when a Plan is approved for execute, the planning agent reviews the Plan against the PRD and updates affected sections; (2) when Examine feedback is categorized as a scope change, the planning agent reviews the feedback and proposes PRD updates (subject to HIL approval). Both invocations use the same agent calling system as all other agent interactions. All PRD changes are recorded in the `change_log` with source attribution (which phase triggered the change) and full diff history. Users can view any historical version of the PRD in the Spec tab.\n\n### 15.2 Agent Orchestration\n\nThe agent orchestration layer manages the lifecycle of agent instances. All agents — planning, coding, and review — are invoked through the same mechanism: the user-configured agent API or CLI for that mode (see Section 6.3). The orchestrator runs a single agent at a time (v1), handling: task selection via `bd ready`, agent assignment via beads' `assignee` field, context assembly (gathering PRD sections, Plan markdowns, and outputs from dependency tasks into the task directory), the two-agent coding/review cycle, branch creation and cleanup, 5-minute inactivity timeout monitoring, and retry logic for failed tasks.\n\n### 15.3 Work Provenance (Beads)\n\nEvery piece of work in OpenSprint is traceable. The beads system captures: which design decision led to a feature, which Plan markdown specified the feature, which tasks implemented it, what the agent reasoned during implementation (via agent session logs), and what feedback was received post-execute. Users can query this provenance at any time by asking \"Why was this built this way?\" and receive a full trace from design decision to deployed code. Beads' built-in audit trail and `discovered-from` dependency type support this traceability natively.\n\n## 16. Non-Functional Requirements\n\n| Category        | Requirement                                                                                                  |\n| --------------- | ------------------------------------------------------------------------------------------------------------ |\n| Performance     | Real-time agent output streaming with < 500ms latency; kanban board updates within 1 second of state changes |\n| Scalability     | Handle projects with up to 500 tasks; single-agent execution in v1, concurrent agents planned for v2         |\n| Reliability     | Agent failures must not corrupt project state; all state changes are transactional and recoverable           |\n| Security        | Code execution in sandboxed environments; user projects isolated at the filesystem level                   |\n| Usability       | First-time users can create a Spec and reach Execute phase within 30 minutes without documentation           |\n| Data Integrity  | Full audit trail of every change via PRD versioning and bead provenance; no data loss on agent crash        |\n| Testing         | Minimum 80% code coverage; all test layers automated; test results visible in real-time                      |\n| Offline Support | All core features (Spec, Plan, Execute, Examine) fully functional without internet connectivity             |",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    },
    "open_questions": {
      "content": "| Phase | Scope                                                                                                                                                                                                                                                                                                                     |\n| ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Alpha | Spec + Plan phases with living PRD; chat interface with planning agent; Plan markdown generation; agent selection during setup; project home screen                                                                                                                                                                     |\n| Beta  | Execute phase with kanban board, single-agent task execution with coding/review cycle, beads integration, agent CLI contract, unit test generation, and error handling                                                                                                                                                      |\n| v1.0  | Full Execute phase with real-time monitoring, comprehensive testing (unit + integration + E2E), HIL configuration, and 5-minute timeout handling                                                                                                                                                                            |\n| v1.1  | Examine phase with feedback ingestion, intelligent mapping, flywheel closure, and Expo.dev deployment integration                                                                                                                                                                                                        |\n| v2.0  | Concurrent multi-agent Execute execution with conflict resolution, conductor agent for context summarization, **Agent Dashboard tab** (view, monitor, and manage all agent status and output including conductor), multi-project support, team collaboration, custom deployment pipelines, regression test suite management |",
      "version": 2,
      "updatedAt": "2026-02-17T07:33:18.682Z"
    }
  },
  "changeLog": [
    {
      "section": "executive_summary",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-2 lines, +0 chars]"
    },
    {
      "section": "goals_and_metrics",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-2 lines, +2 chars]"
    },
    {
      "section": "technical_architecture",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-8 lines, +15 chars]"
    },
    {
      "section": "feature_list",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-8 lines, +47 chars]"
    },
    {
      "section": "data_model",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-2 lines, +6 chars]"
    },
    {
      "section": "api_contracts",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-251 lines, -11907 chars]"
    },
    {
      "section": "non_functional_requirements",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-44 lines, -2178 chars]"
    },
    {
      "section": "open_questions",
      "version": 2,
      "source": "plan",
      "timestamp": "2026-02-17T07:33:18.682Z",
      "diff": "[-51 lines, -9048 chars]"
    }
  ]
}